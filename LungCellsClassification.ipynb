{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Lung Cancer\n",
    "\n",
    "## üìñ Background\n",
    "\n",
    "\n",
    "My task is to build a simple machine learning model that can help classify lung cell images into three groups:\n",
    "\n",
    "- Benign cells\n",
    "- Adenocarcinoma cells\n",
    "- Squamous cells carcinoma\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ü©ª The Data\n",
    "\n",
    "\n",
    "The dataset is <a href=\"https://www.kaggle.com/datasets/rm1000/lung-cancer-histopathological-images/data?select=adenocarcinoma\"> Chest X-Ray Images </a> and contains three main folders:\n",
    "\n",
    "- Adenocarcinoma: 5000 images\n",
    "- Benign: 5000 images \n",
    "- Squamous cell carcinoma: 5000 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rm1000/lung-cancer-histopathological-images?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.55G/1.55G [01:22<00:00, 20.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Asus user\\.cache\\kagglehub\\datasets\\rm1000\\lung-cancer-histopathological-images\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "#Get the data from Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rm1000/lung-cancer-histopathological-images\")\n",
    "\n",
    "print(\"Path to dataset files:\", path) #use this path to extract the data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\" #fill this in with the path from above for faster results next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T20:17:50.013397Z",
     "iopub.status.busy": "2025-09-29T20:17:50.013154Z",
     "iopub.status.idle": "2025-09-29T20:17:58.216862Z",
     "shell.execute_reply": "2025-09-29T20:17:58.215791Z",
     "shell.execute_reply.started": "2025-09-29T20:17:50.013382Z"
    },
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1758723830599,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Will load ResNet18 weights here to help load the images\n\nimport torch\nimport torch.nn as nn\nfrom torchvision.models import resnet18, ResNet18_Weights \nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nweights = ResNet18_Weights.DEFAULT #get the default weights of the model\ntransform_resnet = weights.transforms() #need this to load the images for ResNet\n\ntransform_cnn = transforms.Compose([\n    transforms.Resize((224, 224)),\n    #transforms.RandomRotation(30),\n    #transforms.RandomHorizontalFlip(),\n    transforms.Grayscale(num_output_channels=1), # force grayscale\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])  # center around 0\n])",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Will load ResNet18 weights here to help load the images\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT # get the default weights of the model\n",
    "transform_resnet = weights.transforms() # need this to load the images for ResNet\n",
    "\n",
    "transform_cnn = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #The original size (768, 768) is too large, need to downsize to reduce the compilation time during training\n",
    "    #transforms.RandomRotation(30),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.Grayscale(num_output_channels=1), # force grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # center around 0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T20:18:04.284022Z",
     "iopub.status.busy": "2025-09-29T20:18:04.283614Z",
     "iopub.status.idle": "2025-09-29T20:18:14.186641Z",
     "shell.execute_reply": "2025-09-29T20:18:14.185677Z",
     "shell.execute_reply.started": "2025-09-29T20:18:04.284005Z"
    },
    "executionCancelledAt": null,
    "executionTime": 90,
    "lastExecutedAt": 1758723834544,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Loading the image data and getting the labels:\n\ntrain_path = \"data/chestxrays/train\"\ntest_path = \"data/chestxrays/test\"\n\n#Need 3 channels for ResNet, so will not transform to greyscale:\ntrain_dataset_resnet = datasets.ImageFolder(root=train_path, transform=transform_resnet)\ntest_dataset_resnet  = datasets.ImageFolder(root=test_path, transform=transform_resnet)\n\ntrain_loader_resnet = DataLoader(train_dataset_resnet, batch_size=32, shuffle=True)\ntest_loader_resnet  = DataLoader(test_dataset_resnet, batch_size=32)\n\n#For the CNN model, grayscale works:\ntrain_dataset_cnn = datasets.ImageFolder(root=train_path, transform=transform_cnn)\ntest_dataset_cnn  = datasets.ImageFolder(root=test_path, transform=transform_cnn)\n\ntrain_loader_cnn = DataLoader(train_dataset_cnn, batch_size=32, shuffle=True)\ntest_loader_cnn  = DataLoader(test_dataset_cnn, batch_size=32)\n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Loading the image data and getting the labels:\n",
    "#Using the path from earlier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "full_dataset_resnet = datasets.ImageFolder(root=path, transform=transform_resnet)\n",
    "full_dataset_cnn = datasets.ImageFolder(root=path, transform=transform_cnn)\n",
    "\n",
    "targets_resnet = np.array(full_dataset_resnet.targets)\n",
    "targets_cnn = np.array(full_dataset_cnn.targets)\n",
    "\n",
    "#15000 images are too many to run on cpu so I will only be using a subset of the data\n",
    "subset_dataset_resnet_idx, _ = train_test_split(np.arange(len(targets_resnet)), test_size=0.94, stratify=targets_resnet, random_state=42)\n",
    "subset_dataset_cnn_idx, _ = train_test_split(np.arange(len(targets_cnn)), test_size=0.94, stratify=targets_cnn, random_state=42)\n",
    "\n",
    "#Need to split the dataset into train, test and validation sets, I do this to make sure the classes are balanced\n",
    "train_dataset_resnet_idx, temp_dataset_resnet_idx = train_test_split(subset_dataset_resnet_idx, test_size=0.333, stratify=targets_resnet[subset_dataset_resnet_idx], random_state=42)\n",
    "train_dataset_cnn_idx, temp_dataset_cnn_idx = train_test_split(subset_dataset_resnet_idx, test_size=0.333, stratify=targets_cnn[subset_dataset_cnn_idx], random_state=42)\n",
    "\n",
    "val_dataset_resnet_idx, test_dataset_resnet_idx = train_test_split(temp_dataset_resnet_idx, test_size=0.666, stratify=targets_resnet[temp_dataset_resnet_idx], random_state=42)\n",
    "val_dataset_cnn_idx, test_dataset_cnn_idx = train_test_split(temp_dataset_cnn_idx, test_size=0.666, stratify=targets_cnn[temp_dataset_cnn_idx], random_state=42)\n",
    "\n",
    "train_dataset_resnet = Subset(full_dataset_resnet, train_dataset_resnet_idx)\n",
    "val_dataset_resnet = Subset(full_dataset_resnet, val_dataset_resnet_idx)\n",
    "test_dataset_resnet = Subset(full_dataset_resnet, test_dataset_resnet_idx)\n",
    "\n",
    "train_dataset_cnn = Subset(full_dataset_resnet, train_dataset_cnn_idx)\n",
    "val_dataset_cnn = Subset(full_dataset_resnet, val_dataset_cnn_idx)\n",
    "test_dataset_cnn = Subset(full_dataset_resnet, test_dataset_cnn_idx)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=batch_size, shuffle=True)\n",
    "val_loader_resnet   = DataLoader(val_dataset_resnet, batch_size=batch_size, shuffle=False)\n",
    "test_loader_resnet  = DataLoader(test_dataset_resnet, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cnn   = DataLoader(val_dataset_cnn, batch_size=batch_size, shuffle=False)\n",
    "test_loader_cnn  = DataLoader(test_dataset_cnn, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adenocarcinoma', 'benign', 'squamous_cell_carcinoma']\n",
      "{'adenocarcinoma': 0, 'benign': 1, 'squamous_cell_carcinoma': 2}\n"
     ]
    }
   ],
   "source": [
    "#to see each class\n",
    "print(full_dataset_resnet.classes)           # List of class names in alphabetical order\n",
    "print(full_dataset_resnet.class_to_idx)      # Dictionary: {'class_name': index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:04:24.273810Z",
     "iopub.status.busy": "2025-09-29T17:04:24.273140Z",
     "iopub.status.idle": "2025-09-29T17:04:24.280432Z",
     "shell.execute_reply": "2025-09-29T17:04:24.279416Z",
     "shell.execute_reply.started": "2025-09-29T17:04:24.273783Z"
    },
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1758723879353,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#CNN architecture\nclass CNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1, out_channels=32,\n                            kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2),\n            torch.nn.Conv2d(in_channels=32, out_channels=64,\n                            kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2),\n            torch.nn.Conv2d(in_channels=64, out_channels=64,\n                            kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2),\n            torch.nn.Flatten(),\n            torch.nn.Linear(224 * 224, 32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32, 2)\n        )\n\n    def forward(self, x):\n        return self.model(x)",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#CNN architecture\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32,\n",
    "                            kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                            kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                            kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=64,\n",
    "                            kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(12544, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 3)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=50176, out_features=64, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_cnn = CNN().to(device)\n",
    "print(model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-29T19:45:59.190Z",
     "iopub.execute_input": "2025-09-29T17:31:33.208905Z",
     "iopub.status.busy": "2025-09-29T17:31:33.208570Z"
    },
    "executionCancelledAt": null,
    "executionTime": 392796,
    "lastExecutedAt": 1758726803715,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Training for CNN:\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel_cnn = CNN().to(device)\n\ncriterion_cnn = torch.nn.CrossEntropyLoss()\noptimizer_cnn = torch.optim.Adam(model_cnn.parameters(), lr=0.001, weight_decay=0.01)\n\nepochs = 14\nfor epoch in range(epochs):\n    model_cnn.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader_cnn:\n        inputs, labels = inputs.to(device), labels.long().to(device)\n        optimizer_cnn.zero_grad()\n        outputs = model_cnn(inputs)\n        loss = criterion_cnn(outputs, labels)\n        loss.backward()\n        optimizer_cnn.step()\n        running_loss += loss.item() * inputs.size(0)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")",
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 1.1077 - Validation Accuracy: 0.6400 - Validation Loss: 0.9988\n",
      "Epoch 2/10 - Loss: 0.7013 - Validation Accuracy: 0.7600 - Validation Loss: 0.5836\n",
      "Epoch 3/10 - Loss: 0.4777 - Validation Accuracy: 0.6800 - Validation Loss: 0.6492\n",
      "Epoch 4/10 - Loss: 0.4663 - Validation Accuracy: 0.7700 - Validation Loss: 0.5159\n",
      "Epoch 5/10 - Loss: 0.4333 - Validation Accuracy: 0.8000 - Validation Loss: 0.4924\n",
      "Epoch 6/10 - Loss: 0.4087 - Validation Accuracy: 0.8100 - Validation Loss: 0.4697\n",
      "Epoch 7/10 - Loss: 0.3585 - Validation Accuracy: 0.8200 - Validation Loss: 0.4633\n",
      "Epoch 8/10 - Loss: 0.3413 - Validation Accuracy: 0.8500 - Validation Loss: 0.3875\n",
      "Epoch 9/10 - Loss: 0.2725 - Validation Accuracy: 0.8200 - Validation Loss: 0.4701\n",
      "Epoch 10/10 - Loss: 0.2745 - Validation Accuracy: 0.8600 - Validation Loss: 0.4185\n"
     ]
    }
   ],
   "source": [
    "#Training for CNN:\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_cnn = CNN().to(device)\n",
    "\n",
    "criterion_cnn = torch.nn.CrossEntropyLoss()\n",
    "optimizer_cnn = torch.optim.Adam(model_cnn.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_cnn:\n",
    "        inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "        optimizer_cnn.zero_grad()\n",
    "        outputs = model_cnn(inputs)\n",
    "        loss = criterion_cnn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cnn.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    model_cnn.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    for inputs, labels in val_loader_cnn:\n",
    "        inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "        outputs = model_cnn(inputs)\n",
    "        loss = criterion_cnn(outputs, labels)\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate the accuracy for the classification\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item() \n",
    "\n",
    "    val_acc = correct / len(val_loader_cnn.dataset)\n",
    "    epoch_val_loss = val_loss / len(val_loader_cnn.dataset)\n",
    "    epoch_loss = running_loss / len(train_loader_cnn.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Validation Accuracy: {val_acc:.4f} - Validation Loss: {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4904,
    "lastExecutedAt": 1758726386480,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Evaluation for the CNN model:\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nmodel_cnn.eval()\nall_preds_cnn = []\nall_labels_cnn = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader_cnn:\n        inputs = inputs.to(device)\n        outputs = model_cnn(inputs)\n        #preds = (torch.sigmoid(outputs) > 0.5).float() #for 1 class\n        preds = torch.argmax(outputs, dim=1) #for 2 classes\n        all_preds_cnn.extend(preds.cpu().numpy().ravel())\n        all_labels_cnn.extend(labels.numpy().ravel())\n\nacc_cnn = accuracy_score(all_labels_cnn, all_preds_cnn)\nprec_cnn = precision_score(all_labels_cnn, all_preds_cnn)\nrec_cnn = recall_score(all_labels_cnn, all_preds_cnn)\n\nprint(f\"Accuracy: {acc_cnn:.4f}, Precision: {prec_cnn:.4f}, Recall: {rec_cnn:.4f}\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8850\n",
      "Precision by classes:\n",
      "[0.86440678 0.90540541 0.88059701]\n",
      "Recall by classes\n",
      "[0.77272727 1.         0.88059701]\n"
     ]
    }
   ],
   "source": [
    "#Evaluation for the CNN model:\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "model_cnn.eval()\n",
    "all_preds_cnn = []\n",
    "all_labels_cnn = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_cnn:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_cnn(inputs)\n",
    "        #preds = (torch.sigmoid(outputs) > 0.5).float() #for 1 class\n",
    "        preds = torch.argmax(outputs, dim=1) #for 2 classes\n",
    "        all_preds_cnn.extend(preds.cpu().numpy().ravel())\n",
    "        all_labels_cnn.extend(labels.numpy().ravel())\n",
    "\n",
    "acc_cnn = accuracy_score(all_labels_cnn, all_preds_cnn)\n",
    "prec_cnn = precision_score(all_labels_cnn, all_preds_cnn, average = None)\n",
    "rec_cnn = recall_score(all_labels_cnn, all_preds_cnn, average = None)\n",
    "\n",
    "print(f\"Accuracy: {acc_cnn:.4f}\")\n",
    "print(\"Precision by classes:\")\n",
    "print(prec_cnn)\n",
    "print(\"Recall by classes\")\n",
    "print(rec_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T20:24:59.868118Z",
     "iopub.status.busy": "2025-09-29T20:24:59.867834Z",
     "iopub.status.idle": "2025-09-29T20:25:00.537831Z",
     "shell.execute_reply": "2025-09-29T20:25:00.536188Z",
     "shell.execute_reply.started": "2025-09-29T20:24:59.868103Z"
    },
    "executionCancelledAt": null,
    "executionTime": 6860,
    "lastExecutedAt": 1758717282409,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#ResNet\nmodel_resnet = resnet18(weights=weights)\nprint(model_resnet.fc) #1000 classes\n\n#It needs to classify into two classes: \"healthy\" and \"tb\", so:\nnum_classes = 2 \nmodel_resnet.fc = nn.Linear(model_resnet.fc.in_features, num_classes)\nprint(model_resnet.fc) #2 classes",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 59,
      "type": "stream"
     },
     "2": {
      "height": 38,
      "type": "stream"
     }
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n",
      "Linear(in_features=512, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#ResNet\n",
    "model_resnet = resnet18(weights=weights)\n",
    "print(model_resnet.fc) #1000 classes\n",
    "\n",
    "#It needs to classify into two classes: \"healthy\" and \"tb\", so:\n",
    "num_classes = 3 \n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, num_classes)\n",
    "print(model_resnet.fc) #2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T20:27:39.329879Z",
     "iopub.status.busy": "2025-09-29T20:27:39.329594Z",
     "iopub.status.idle": "2025-09-29T20:38:20.807445Z",
     "shell.execute_reply": "2025-09-29T20:38:20.806648Z",
     "shell.execute_reply.started": "2025-09-29T20:27:39.329859Z"
    },
    "executionCancelledAt": null,
    "executionTime": 263638,
    "lastExecutedAt": 1758717592795,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Training step for ResNet\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_resnet = model_resnet.to(device)\n\ncriterion_resnet = nn.CrossEntropyLoss()  # for two classes\noptimizer_resnet = optim.Adam(model_resnet.parameters(), lr=1e-4)\n\nepochs = 5\nfor epoch in range(epochs):\n    model_resnet.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.long().to(device)\n        optimizer_resnet.zero_grad()\n        outputs = model_resnet(inputs)\n        print(outputs.shape, labels.shape, labels.dtype)\n        loss = criterion_resnet(outputs, labels)\n        loss.backward()\n        optimizer_resnet.step()\n        running_loss += loss.item() * inputs.size(0)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")",
    "outputsMetadata": {
     "0": {
      "height": 570,
      "type": "stream"
     }
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 0.0659 - Validation Accuracy: 97.0000 - Validation Loss: 6.4628\n",
      "Epoch 2/5 - Loss: 0.0375 - Validation Accuracy: 99.0000 - Validation Loss: 3.3089\n",
      "Epoch 3/5 - Loss: 0.0198 - Validation Accuracy: 97.0000 - Validation Loss: 5.2727\n",
      "Epoch 4/5 - Loss: 0.0082 - Validation Accuracy: 96.0000 - Validation Loss: 8.4988\n",
      "Epoch 5/5 - Loss: 0.0093 - Validation Accuracy: 99.0000 - Validation Loss: 6.0331\n"
     ]
    }
   ],
   "source": [
    "#Training step for ResNet\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "criterion_resnet = nn.CrossEntropyLoss()  # for two classes\n",
    "optimizer_resnet = optim.Adam(model_resnet.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_resnet:\n",
    "        inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "        optimizer_resnet.zero_grad()\n",
    "        outputs = model_resnet(inputs)\n",
    "        loss = criterion_resnet(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_resnet.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    model_resnet.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    for inputs, labels in val_loader_resnet:\n",
    "        inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "        outputs = model_resnet(inputs)\n",
    "        loss = criterion_cnn(outputs, labels)\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate the accuracy for the classification\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader_resnet.dataset)\n",
    "    epoch_val_loss = val_loss / len(val_loader_resnet.dataset)\n",
    "    epoch_loss = running_loss / len(train_loader_resnet.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Validation Accuracy: {val_acc:.4f} - Validation Loss: {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7068,
    "lastExecutedAt": 1758717697577,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Evaluation on the test data\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nmodel_resnet.eval()\nall_preds_resnet = []\nall_labels_resnet = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        outputs = model_resnet(inputs)\n        #preds = (torch.sigmoid(outputs) > 0.5).float() #for 1 class\n        preds = torch.argmax(outputs, dim=1) #for 2 classes\n        all_preds_resnet.extend(preds.cpu().numpy().ravel())\n        all_labels_resnet.extend(labels.numpy().ravel())\n\nacc_resnet = accuracy_score(all_labels, all_preds)\nprec_resnet = precision_score(all_labels, all_preds)\nrec_resnet = recall_score(all_labels, all_preds)\n\nprint(f\"Accuracy: {acc_resnet:.4f}, Precision: {prec_resnet:.4f}, Recall: {rec_resnet:.4f}\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9950\n",
      "Precision by classes:\n",
      "[0.98507463 1.         1.        ]\n",
      "Recall by classes\n",
      "[1.         1.         0.98507463]\n"
     ]
    }
   ],
   "source": [
    "#Evaluation on the test data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "model_resnet.eval()\n",
    "all_preds_resnet = []\n",
    "all_labels_resnet = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_resnet:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_resnet(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1) #for 2 classes\n",
    "        all_preds_resnet.extend(preds.cpu().numpy().ravel())\n",
    "        all_labels_resnet.extend(labels.numpy().ravel())\n",
    "\n",
    "acc_resnet = accuracy_score(all_labels_resnet, all_preds_resnet)\n",
    "prec_resnet = precision_score(all_labels_resnet, all_preds_resnet, average = None)\n",
    "rec_resnet = recall_score(all_labels_resnet, all_preds_resnet, average = None)\n",
    "\n",
    "print(f\"Accuracy: {acc_resnet:.4f}\")\n",
    "print(\"Precision by classes:\")\n",
    "print(prec_resnet)\n",
    "print(\"Recall by classes\")\n",
    "print(rec_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 351,
    "lastExecutedAt": 1758726392951,
    "lastExecutedByKernel": "6204ac7f-30a9-43ac-9c7f-211e587e0f79",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Evaluation metrics for each model with confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nconfusion_matrix_cnn = confusion_matrix(all_labels_cnn, all_preds_cnn)\nconfusion_matrix_resnet = confusion_matrix(all_labels_resnet, all_preds_resnet)\n\nsensitivity_cnn = confusion_matrix_cnn[1][1] #How many TB cases your model correctly finds.\nspecificity_cnn = confusion_matrix_cnn[0][0] #How many healthy cases your model correctly identifies.\nppv_cnn = confusion_matrix_cnn[1][1] / 50 #When your model says ‚ÄúTB‚Äù, how often it‚Äôs right.\nnpv_cnn = confusion_matrix_cnn[0][0] / 50 #When your model says ‚ÄúHealthy‚Äù, how often it‚Äôs right.\n\nsensitivity_resnet = confusion_matrix_resnet[1][1] #How many TB cases your model correctly finds.\nspecificity_resnet = confusion_matrix_resnet[0][0] #How many healthy cases your model correctly identifies.\nppv_resnet = confusion_matrix_resnet[1][1] / 50 #When your model says ‚ÄúTB‚Äù, how often it‚Äôs right.\nnpv_resnet = confusion_matrix_resnet[1][1] / 50 #When your model says ‚ÄúHealthy‚Äù, how often it‚Äôs right.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(100,100))\nfigure, axis = plt.subplots(1, 2, sharey= True, sharex=True)\nsns.heatmap(confusion_matrix_cnn, ax=axis[0], vmin=0, vmax=50, annot=True)\nplt.suptitle(\"Confusion Matrix For Each Model\")\naxis[0].set_title(\"CNN\")\nsns.heatmap(confusion_matrix_resnet, ax=axis[1], vmin=0, vmax=50, annot=True)\naxis[1].set_title(\"ResNet\")\nplt.show()"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 40000x20000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluation metrics for each model with confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix_cnn = confusion_matrix(all_labels_cnn, all_preds_cnn)\n",
    "confusion_matrix_resnet = confusion_matrix(all_labels_resnet, all_preds_resnet)\n",
    "\n",
    "sensitivity_cnn = confusion_matrix_cnn[1][1] #How many TB cases your model correctly finds.\n",
    "specificity_cnn = confusion_matrix_cnn[0][0] #How many healthy cases your model correctly identifies.\n",
    "ppv_cnn = confusion_matrix_cnn[1][1] / 50 #When your model says ‚ÄúTB‚Äù, how often it‚Äôs right.\n",
    "npv_cnn = confusion_matrix_cnn[0][0] / 50 #When your model says ‚ÄúHealthy‚Äù, how often it‚Äôs right.\n",
    "\n",
    "\n",
    "sensitivity_resnet = confusion_matrix_resnet[1][1] #How many TB cases your model correctly finds.\n",
    "specificity_resnet = confusion_matrix_resnet[0][0] #How many healthy cases your model correctly identifies.\n",
    "ppv_resnet = confusion_matrix_resnet[1][1] / 50 #When your model says ‚ÄúTB‚Äù, how often it‚Äôs right.\n",
    "npv_resnet = confusion_matrix_resnet[1][1] / 50 #When your model says ‚ÄúHealthy‚Äù, how often it‚Äôs right.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(400,200))\n",
    "figure, axis = plt.subplots(1, 2, sharey= True, sharex=True)\n",
    "sns.heatmap(confusion_matrix_cnn, ax=axis[0], vmin=0, annot=True)\n",
    "plt.suptitle(\"Confusion Matrix For Each Model\")\n",
    "axis[0].set_title(\"CNN\")\n",
    "sns.heatmap(confusion_matrix_resnet, ax=axis[1], vmin=0, annot=True)\n",
    "axis[1].set_title(\"ResNet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above visual, we can observe that the CNN model tends to label benign images correctly, but it missrepresents the other two categories.\n",
    "\n",
    "For the ResNet models, the predictions are balanced with 99.5% accuracy, a satisfying result. Using the full dataset would probably yeald a similar result."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5712571,
     "sourceId": 9408268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
